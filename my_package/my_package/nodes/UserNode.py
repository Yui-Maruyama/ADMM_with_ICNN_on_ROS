import rclpy
from rclpy.node import Node
from std_msgs.msg import Float32
from std_msgs.msg import Int32
from std_msgs.msg import String
from std_msgs.msg import Bool
import threading
import time
from my_package.PICNN import myPICNN
import random
import torch
import torch.optim as optim
from my_package.ADMM_utils import *
import os

class UserNode(Node):
    def __init__(self):
        super().__init__('ikisugi')
        # self.user_id = user_id
        # self.neighbor = user_list
        # self.bandwidth = bandwidth

        # self.topic_name = f'user_{self.user_id}/param'
        # self.publisher = self.create_publisher(Float32, self.topic_name, 10)
        # self.get_logger().info(f'Publishing to: {self.topic_name}')

        # self.user_id = self.declare_parameter('user_id', 0).value
        # self.bandwidth = self.declare_parameter('bandwidth', {}).value
        # self.neighbors = self.declare_parameter('neighbors', []).value
        # self.total_users = self.declare_parameter('total_users', []).value
        # self.scene = self.declare_parameter('scene', 0).value

         # Declare parameters first (optional but recommended)
         # ã©ã†ã‚„ã‚‰ç©ºã®é…åˆ—ã ã¨byteå‹ã¨èª¤èªã•ã‚Œã‚‹ã‚‰ã—ã„
        self.declare_parameter('neighbors', [0])
        self.declare_parameter('bandwidth', [0.0])
        self.declare_parameter('total_users', 0)
        self.declare_parameter('scene', 0)
        self.declare_parameter('user_id', -1)
        self.declare_parameter('start_time', 0.0)

        # Retrieve the parameters
        self.neighbors = self.get_parameter('neighbors').get_parameter_value().integer_array_value
        self.bandwidth = self.get_parameter('bandwidth').get_parameter_value().double_array_value
        self.bandwidth = torch.tensor(self.bandwidth)
        self.total_users = self.get_parameter('total_users').get_parameter_value().integer_value
        self.scene = self.get_parameter('scene').get_parameter_value().integer_value
        self.user_id = self.get_parameter('user_id').get_parameter_value().integer_value
        self.start_time = self.get_parameter('start_time').get_parameter_value().double_value

        self.get_logger().info(
            f"Started user {self.user_id} with neighbors={self.neighbors}, "
            f"bandwidth={self.bandwidth}, scene={self.scene}, total_users={self.total_users}")


        # self.get_logger().info(f'User ID: {self.user_id}')

        self.topic_name = f'user_{self.user_id}/param'
        self.publisher = self.create_publisher(Float32, self.topic_name, 10)
        # self.get_logger().info(f'Publishing to: {self.topic_name}')

        # ä»–ã®ãƒ¦ãƒ¼ã‚¶ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’ã‚µãƒ–ã‚¹ã‚¯ãƒ©ã‚¤ãƒ–
        for other_user_id in self.neighbors:
            if other_user_id != self.user_id:
                topic = f'user_{other_user_id}/param'
                self.create_subscription(Float32, topic, self.create_callback(other_user_id), 10)
                # self.get_logger().info(f'Subscribed to: {topic}')

        # ã‚·ãƒ¼ãƒ³ã¨ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        # self.scene = scene
        match self.scene:
            case 1:
                self.model = myPICNN(22, 10, 100)
                self.model.load_state_dict(torch.load('../model/model_scene_1.pth'))
                self.model.train()
            case 2:
                self.model = myPICNN(16, 10, 100)
                self.model.load_state_dict(torch.load('../model/model_scene_2.pth'))
                self.model.train()
            case 3:
                self.model = myPICNN(30, 10, 100)
                self.model.load_state_dict(torch.load('../model/model_scene_3.pth'))
                self.model.train()

        #ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å®¹é‡èª­ã¿è¾¼ã¿
        self.max_capacities = []
        print(os.getcwd())
        capacity_info_file = "../ADMM_ROS/max_capacity.txt"
        with open(capacity_info_file, 'r') as file:
            for line in file:
                self.numbers = list(map(float, line.split()))
                self.max_capacities.append(torch.tensor(self.numbers, requires_grad=False))
        self.max_capacity = self.max_capacities[self.scene - 1]

        # å¤‰æ•°ã®åˆæœŸåŒ–
        self.x = torch.tensor(np.zeros(len(self.max_capacity) * 2), requires_grad=True)
        self.mu = {user_id: torch.tensor([0.0]) for user_id in self.neighbors}
        self.s = {user_id: torch.tensor([0.0]) for user_id in self.neighbors}
        self.rho = 1.0
        self.x_list = []
        self.mu_list = []
        self.s_list = []
        self.scores = []
        self.step = 0

        # ä»–ãƒ¦ãƒ¼ã‚¶ã®é€šä¿¡è·¯ä½¿ç”¨é‡
        # è¦ç´ æ•°1ã®ãƒ†ãƒ³ã‚½ãƒ«ï¼ˆåˆæœŸå€¤ã¯ä¾‹ã¨ã—ã¦0.0ï¼‰ã‚’ä½œæˆã—ã€ãƒ¦ãƒ¼ã‚¶IDã‚’ã‚­ãƒ¼ã¨ã™ã‚‹è¾æ›¸ã‚’ç”Ÿæˆ
        self.other_usages = {user_id: torch.tensor([0.0]) for user_id in self.neighbors}

        # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶
        self.optimizer = optim.Adam([self.x], lr=0.01)

        # çµæœè¨˜è¼‰ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆæœŸåŒ–
        self.result_file_name = f"../result_user_{self.total_users}/user_{self.user_id}.txt"
        with open(self.result_file_name, mode = 'w') as f:
            f.write(f"user {self.user_id}   scene:{self.scene}\n")

        # ã‚¹ã‚¿ãƒ¼ãƒˆã‚’åŒæœŸã•ã›ã‚‹éƒ¨åˆ†
        # self.optimization_started = False
        # self.optimization_thread = None
        # ãƒ•ãƒ©ã‚°ã§ /start ã‚’å¾…æ©Ÿ
        self.start_event = threading.Event()

        # startãƒˆãƒ”ãƒƒã‚¯ã®ã‚µãƒ–ã‚¹ã‚¯ãƒ©ã‚¤ãƒ
        self.subscription = self.create_subscription(
            Bool,
            '/start',
            self.start_callback,
            10
        )

        # coordinator ã«æº–å‚™å®Œäº†ã‚’é€šçŸ¥
        ready_msg = Int32()
        ready_msg.data = self.user_id
        self.ready_pub = self.create_publisher(Int32, '/ready', 10)
        self.ready_pub.publish(ready_msg)
        self.get_logger().info(f'User {self.user_id} is ready.')

        # æœ€é©åŒ–ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹ï¼ˆä¸­ã§ .wait() ã§ãƒ–ãƒ­ãƒƒã‚¯ï¼‰
        self.optimization_thread = threading.Thread(target=self.optimization_loop)
        self.optimization_thread.start()

        # çµ‚äº†æ¡ä»¶ã®é€šçŸ¥ç”¨
        self._finished = False
        # self.finished_pub = self.create_publisher(Int32, "finished_users", 10)
        # æ¯ç§’çµ‚äº†åˆ¤å®šã‚’è¡Œã†ã‚¿ã‚¤ãƒãƒ¼ï¼ˆãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰å´ï¼‰
        self.create_timer(1.0, self._check_shutdown)



    def create_callback(self, other_user_id):
        def callback(msg):
            if self.user_id == 100:
                self.get_logger().info(f'Received from user_{other_user_id}: {msg.data}')
        return callback
    
    
    # æœ€é©åŒ–ã‚’é–‹å§‹ã™ã‚‹ãŸã‚ã®é–¢æ•°
    def start_callback(self, msg: Bool):
        self.get_logger().info(f'Start signal received ({msg.data}). Beginning optimization...')
        if msg.data:
            # self.get_logger().info('Start signal received. Beginning optimization...')
            self.start_event.set()


    def optimization_loop(self):
        self.get_logger().info('Waiting for /start...')
        self.start_event.wait()  # ãƒ–ãƒ­ãƒƒã‚¯ã—ã¦å¾…ã¤
        self.get_logger().info('Start confirmed. Running optimization.')

        while rclpy.ok() and (not is_converged(self.scores, self.step)):
            # TODO: æœ€é©åŒ–å‡¦ç†ã‚’ã“ã“ã«è¨˜è¿°
            # xã®æ›´æ–°
            # print(f"bandwidth constraints for user {self.user_id}: {self.bandwidth}")
            x = local_optimize(self.user_id, self.x, self.other_usages, self.mu, self.s, self.rho, self.optimizer, self.model, self.neighbors, self.max_capacity, self.bandwidth)
            self.x = x.clone().requires_grad_()
            self.optimizer = optim.Adam([self.x], lr=0.01)

            # sã®æ›´æ–°
            self.s = update_s(self.user_id, self.s, self.mu, self.x, self.other_usages, self.neighbors, self.max_capacity, self.scene, self.rho, self.bandwidth)

            # muã®æ›´æ–°
            self.mu = update_mu(self.user_id, self.s, self.x, self.mu, self.max_capacity, self.neighbors, self.scene, self.other_usages, self.bandwidth)

            # ã‚¹ã‚³ã‚¢ã®æ›´æ–°
            self.scores, self.x_list, self.mu_list, self.s_list = update_score(self.model, self.x, self.mu, self.s, self.x_list, self.mu_list, self.s_list, self.scores, self.result_file_name, time.time() - self.start_time, ctx = torch.tensor(1))

            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒˆãƒ”ãƒƒã‚¯ã«é…ä¿¡
            publish_usage(self, self.x, self.max_capacity, self.other_usages, self.publisher)

            # ä»Šã¯å˜ã«ã‚¹ãƒªãƒ¼ãƒ—
            # time.sleep(1.0)

            self.step += 1
        
        # msg = Int32()
        # msg.data = self.user_id
        # self.finished_pub.publish(msg)
        self._finished = True  # ğŸ”¸ çµ‚äº†ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
        self.get_logger().info(f"User {self.user_id} finished. Shutting down.")
        # 1s å¾Œã«å®‰å…¨ã« destroy
        # self.create_timer(1.0, self._safe_shutdown)
        # self.destroy_node()


    # æº–å‚™å®Œäº†ã‚’ç®¡ç†ãƒãƒ¼ãƒ‰ã«é€šçŸ¥
    def publish_ready_once(self):
        if not self.ready:
            msg = String()
            msg.data = self.user_id
            self.ready_pub.publish(msg)
            self.get_logger().info(f'{self.user_id} published ready.')
            self.ready = True

    
    def _check_shutdown(self):
        if self._finished:
            self.get_logger().info("Shutting down node...")
            self.destroy_node()
            rclpy.shutdown()  # ğŸ”¸ ã“ã‚Œã«ã‚ˆã‚Š spin() ãŒæŠœã‘ã¦ãƒ—ãƒ­ã‚°ãƒ©ãƒ çµ‚äº†